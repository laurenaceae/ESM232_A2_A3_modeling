---
title: 'Assignment 5: Calibration'
author: "Mia Guarnieri, Lauren Harris, Alia Ajina"
date: "2023-05-11"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: journal
    code_folding: show
    smooth_scroll: yes
    collapsed: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# Installing required packages
library(sensitivity)
library(tidyverse)
library(lubridate)
library(reldist)
library(purrr)
library(ggpubr)
library(here)
```

## Testing new metric 

Modeled minus observed drought days (days with < 0.5 mm of streamflow).

```{r drought days}
# Read in sager data
sager <- read.table("../Data/sager.txt", header=T)

# Add and mutate data
sager = sager %>% mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")

# Sourcing our function
source(here("R", "drought_days.R"))

# Testing our function
dd_test <- drought_days(sager)
```

## Creating and calibrating combined metric

Sum of correlation between modeled and observed wet days (> 10mm of streamflow) and modeled and observed dry days (< 0.5mm of streamflow). Min = -2 (perfectly inverse correlation of modeled and observed data for either wet or dry days) max = 2 (perfect correlation of modeled and observed data for both wet and dry days).

```{r combined metric}

source(here("R", "combined_metric.R"))

cm <- combined_metric(m = sager$model, obs = sager$obs, wy = sager$wy)

# Read in msage data
msage <- read.table("../Data/sagerm.txt", header=T)

# Organize msage data
nsim = ncol(msage)
snames = sprintf("S%d",seq(from=1, to=nsim))
colnames(msage) = snames

# Use date from our earlier output
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# Add observed data
msage <- left_join(msage, sager[,c("obs","date")], by = c("date"))

# Creating subset to split the sample calibration
short_msage <- subset(msage, wy < 1975)

# Computing performance measures for output from all parameters
res <- short_msage %>% 
  select(!c("date","month","year","day", "obs", "wy")) %>%
  map_df(combined_metric, obs = short_msage$obs, wy = short_msage$wy) %>% 
  pivot_longer(cols = c(1:101),
               names_to = "metric",
               values_to = "values")

# Determining our best and worst parameter set
# Best parameter set
best <- res$metric[res$values == max(res$values)]

# Worst parameter set
worst <- res$metric[res$values == min(res$values)]
```

## Plot

```{r}
# graph range of performance measures
ggplot(res) +
  geom_histogram(aes(x = values), col = "lightgrey") +
  labs(x = "Combined Metric",
       y = "Count",
       title = "Sum of correlation between modeled and observed extreme wet and dry days") +
  theme_minimal()

# running the model forward so we can look at the full time series

# lets start with streamflow estimates from best performing parameter set
 ggplot(msage, aes(date, msage[,best])) + 
   geom_line(aes(col = "Modeled (S10)")) +
   geom_line(aes(date, obs, col= "Observed")) +
   theme_minimal() +
   scale_color_manual(values=c("black", "red"))+
   labs(x = "Date",
        y = "Streamflow (mm/day)",
        title = "Modeled vs Observed Streamflow Over Time",
        col = "Data Source")
```


## Determination of Best and Worst Parameter Sets

We determined that our best parameter set was `r best` and our worst parameter set was `r worst`, based on our combined metric of the sum of correlation between modeled and observed extreme wet and dry days. We chose these metrics because we wanted to be certain that our model could account for extremes in streamflow during drought periods or periods of unusually high streamflow. Based on our calibration analysis, the majority of models performed well, with combined metric values of close to 1.5 on a scale of -2 to 2. The median combined metric value of the 101 tested parameter sets was `r round(median(res$values), 2)`.
